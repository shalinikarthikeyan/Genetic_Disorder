{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPXHc3UMSbKU8F8fCdgtKoI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"eXVfDEcgETsC","executionInfo":{"status":"ok","timestamp":1748966452456,"user_tz":-330,"elapsed":7807,"user":{"displayName":"Shalini Karthykeyan","userId":"09673018992908716188"}},"outputId":"b7d90457-55e7-4d2c-f2b9-997fb138c447"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 1.8344 - val_accuracy: 0.0000e+00 - val_loss: 3.9361\n","Epoch 2/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.2500 - loss: 2.1997 - val_accuracy: 0.0000e+00 - val_loss: 4.0106\n","Epoch 3/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - accuracy: 0.2500 - loss: 1.3141 - val_accuracy: 0.0000e+00 - val_loss: 4.1144\n","Epoch 4/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.5000 - loss: 1.2620 - val_accuracy: 0.0000e+00 - val_loss: 3.5140\n","Epoch 5/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 1.0000 - loss: 0.5499 - val_accuracy: 0.0000e+00 - val_loss: 3.5318\n","Epoch 6/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.4681 - val_accuracy: 0.0000e+00 - val_loss: 3.5924\n","Epoch 7/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.5000 - loss: 0.9562 - val_accuracy: 0.0000e+00 - val_loss: 3.4860\n","Epoch 8/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.7500 - loss: 0.5992 - val_accuracy: 0.0000e+00 - val_loss: 3.5148\n","Epoch 9/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 0.2459 - val_accuracy: 0.0000e+00 - val_loss: 3.7848\n","Epoch 10/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - accuracy: 1.0000 - loss: 0.3716 - val_accuracy: 0.0000e+00 - val_loss: 4.2338\n","It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://ece86cf08035abe8cb.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://ece86cf08035abe8cb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":9}],"source":["import os\n","import gradio as gr\n","import numpy as np\n","import pandas as pd\n","import cv2\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from PIL import Image\n","\n","# 📁 Load CSV Data\n","df = pd.read_csv(\"/content/synthetic_genetic_disorder_data.csv\")\n","\n","# 🧠 Encode labels\n","label_encoder = LabelEncoder()\n","df[\"Label\"] = label_encoder.fit_transform(df[\"Disease\"])\n","disease_mapping = {i: name for i, name in enumerate(label_encoder.classes_)}\n","\n","# 🖼️ Load and preprocess all images\n","image_data = []\n","labels = []\n","\n","for idx, row in df.iterrows():\n","    img_path = os.path.join(\"/content\", row[\"ImageFile\"])  # Change if image path is different\n","    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","\n","    if img is not None:\n","        img = cv2.resize(img, (128, 128))\n","        img = img / 255.0\n","        img = img.reshape(128, 128, 1)\n","        image_data.append(img)\n","        labels.append(row[\"Label\"])\n","    else:\n","        print(f\"Failed to load image: {img_path}\")\n","\n","# ✅ Convert to arrays\n","image_data = np.array(image_data)\n","labels = to_categorical(np.array(labels))\n","\n","# 🧠 CNN Model\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n","    MaxPooling2D(),\n","    Dropout(0.25),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D(),\n","    Flatten(),\n","    Dense(64, activation='relu'),\n","    Dropout(0.5),\n","    Dense(labels.shape[1], activation='softmax')\n","])\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# 🏋️ Train model\n","X_train, X_test, y_train, y_test = train_test_split(image_data, labels, test_size=0.2, random_state=42)\n","model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n","\n","# 🔍 Predict Function\n","def predict_from_image_only(uploaded_img):\n","    img = uploaded_img.convert(\"L\").resize((128, 128))\n","    img_array = np.array(img) / 255.0\n","    img_array = img_array.reshape(1, 128, 128, 1)\n","\n","    prediction = model.predict(img_array)[0]\n","    predicted_class = int(np.argmax(prediction))\n","    disease_name = disease_mapping.get(predicted_class, \"Unknown\")\n","\n","    return f\"Predicted Disease: {disease_name}\"\n","\n","# 🧪 Gradio Interface\n","iface = gr.Interface(\n","    fn=predict_from_image_only,\n","    inputs=gr.Image(type=\"pil\", label=\"Upload an Image\"),\n","    outputs=gr.Textbox(label=\"Prediction Result\"),\n","    title=\"Image-Only Genetic Disease Predictor\",\n","    description=\"Upload a medical image to predict the genetic disorder.\"\n",")\n","\n","iface.launch()\n"]}]}